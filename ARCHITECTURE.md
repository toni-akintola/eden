# EDEN Architecture Documentation

This document provides a detailed technical overview of EDEN's architecture, design decisions, and implementation details.

## Table of Contents

- [System Overview](#system-overview)
- [Core Components](#core-components)
- [Data Flow](#data-flow)
- [Key Design Decisions](#key-design-decisions)
- [Performance Considerations](#performance-considerations)
- [Extension Points](#extension-points)

## System Overview

EDEN is built around an evolutionary algorithm where:
1. **Organisms** represent complete queue mechanism specifications
2. **Fitness** is evaluated via discrete-event simulation
3. **Mutations** are generated by LLMs (GPT-5.1) rather than random operators
4. **Selection** applies pressure to keep only high-performing organisms

```
┌─────────────────┐
│   Population    │
│   (Database)    │
└────────┬────────┘
         │
         ├─ Sample Parent + Inspirations
         │
         ▼
┌─────────────────┐
│  LLM Mutator    │
│  (GPT-5.1)      │
└────────┬────────┘
         │
         ├─ Generate Child Organism
         │
         ▼
┌─────────────────┐
│ Queue Simulator │
│   (DES Engine)   │
└────────┬────────┘
         │
         ├─ Evaluate Fitness
         │
         ▼
┌─────────────────┐
│   Evaluator     │
│  (Welfare Calc) │
└────────┬────────┘
         │
         ├─ W = (1-α)·R·E[μ_k] + α·(E[μ_k]·V - E[k]·C)
         │
         ▼
┌─────────────────┐
│   Selection     │
│  (Top 10%)      │
└────────┬────────┘
         │
         └─ Add to Population
```

## Core Components

### 1. `main.py` - Evolution Orchestrator

**Responsibilities:**
- CLI interface and parameter parsing
- Evolution loop coordination
- Worker pool management (ThreadPoolExecutor)
- Result aggregation and output

**Key Functions:**
- `run_evolution()`: Main evolutionary loop
- `evaluate_organism()`: Wraps simulation and fitness calculation
- `mutate_and_evaluate()`: Single mutation + evaluation pipeline
- `crossover_and_evaluate()`: Single crossover + evaluation pipeline

**Design Notes:**
- Uses `ThreadPoolExecutor` for parallel evaluation (GIL-limited, but sufficient for I/O-bound LLM calls)
- Implements batch processing: accumulates children, then applies selection pressure
- Tracks history for visualization and analysis

### 2. `database.py` - Population Management

**Responsibilities:**
- Thread-safe organism storage
- Fitness-weighted sampling
- Top-k tracking for inspirations
- Population pruning

**Key Classes:**
- `Organism`: Dataclass representing a queue mechanism
- `MutationRecord`: Tracks what changed in a mutation
- `Database`: Thread-safe population container

**Key Features:**
- **Fitness-Weighted Sampling**: Higher fitness → higher selection probability
- **Recency-Weighted Inspirations**: Recent high performers more likely to inspire
- **Incremental Weight Caching**: Avoids O(N) recalculation on each sample
- **Heap-Based Top-K**: O(log k) lookup for best organisms

**Thread Safety:**
- Uses `threading.Lock` for all mutations
- Safe for concurrent reads/writes from worker threads

### 3. `mutator.py` - LLM-Guided Mutation

**Responsibilities:**
- Constructing mutation prompts
- Calling GPT-5.1 API
- Adaptive mutation strength control
- Crossover implementation

**Key Classes:**
- `Mutator`: Main mutation orchestrator
- `AdaptiveMutationController`: Temperature-based exploration control

**Mutation Process:**
1. Build prompt with parent, inspirations, lineage history
2. Add mutation strength guidance (small/medium/large/radical)
3. Call GPT-5.1 with structured output format
4. Parse response into new organism
5. Create mutation record tracking changes

**Adaptive Control:**
- **Temperature** τ ∈ [0.3, 3.0] controls exploration
- **Cool Down**: τ ← τ × 0.95 when fitness improves (exploit)
- **Heat Up**: τ ← τ × 1.1 when stagnant (explore)
- **Mutation Strength**: Maps temperature to LLM guidance

**Crossover:**
- Uniform crossover: randomly selects each trait from one of two parents
- Probability increases with temperature (more exploration → more crossover)

### 4. `queue_simulator.py` - Discrete-Event Simulation

**Responsibilities:**
- Implementing Che-Tercieux queue model
- Agent belief updating (Bayesian)
- Event scheduling and processing
- Stationary distribution computation

**Key Classes:**
- `QueueSimulator`: Main simulation engine
- `Agent`: Represents an agent with belief distribution

**Simulation Algorithm:**
1. Initialize queue state (empty)
2. For each event:
   - Compute total rate: λ·x_k + μ·1_{k>0} + Σ y_{k,ℓ}
   - Draw time to next event: Exp(total_rate)
   - Select event type proportionally to rates
   - Update state (arrival/service/exit)
   - Update agent beliefs (Bayesian)
3. Record time spent at each queue length k
4. Compute stationary distribution: p_k = time_at_k / total_time

**Belief Updating:**
- Agents maintain belief distribution γ̃_t^ℓ over position ℓ
- Updated via Bayes' rule on service events
- Different update rules for FCFS/LIFO/SIRO

**Information Rules:**
- **Full Information**: Agents observe exact k
- **No Information**: Agents use expected k from stationary distribution
- **Coarse Information**: Agents observe binned signal (short/medium/long)

### 5. `evaluator.py` - Welfare Calculation

**Responsibilities:**
- Computing welfare score from simulation results
- Implementing Che-Tercieux objective function

**Welfare Function:**
```
W = (1-α)·R·E[μ_k] + α·(E[μ_k]·V - E[k]·C)
```

Where:
- E[μ_k] = expected service flow rate
- E[k] = expected queue length
- α = welfare weight (0.5 = equal weight)
- R, V, C = exogenous parameters

### 6. `evolve_types.py` - Type Definitions

**Responsibilities:**
- Pydantic models for type safety
- Enum definitions (QueueDiscipline, InformationRule)
- Agent class with belief updating logic

**Key Types:**
- `CheTercieuxQueueModel`: Complete model specification
- `SimulationResults`: Output from DES
- `EntryExitRule`: Policy functions
- `PrimitiveProcess`: Arrival/service rate functions

### 7. `utils.py` - Utilities

**Responsibilities:**
- Parsing code strings to functions
- Building mutation prompts
- Creating mutation records

**Key Functions:**
- `parse_code_to_function()`: Converts lambda string to callable
- `build_mutation_prompt()`: Constructs comprehensive prompt for LLM
- `create_mutation_record()`: Tracks what changed in mutation

**Security Note:**
- Currently uses `eval()` for code parsing (security risk)
- Should be replaced with AST parsing for production use

### 8. `visualize.py` - Visualization

**Responsibilities:**
- Plotting fitness progression
- Population statistics
- Strategy comparisons
- Summary reports

**Outputs:**
- `fitness_progression.png`: Fitness over generations
- `population_stats.png`: Distribution plots
- `evolution_report.txt`: Text summary

## Data Flow

### Evolution Loop

```
1. Initialize
   ├─ Create seed organism (random)
   ├─ Evaluate seed → fitness
   └─ Add to database

2. Evolution Step (repeat N times)
   ├─ Sample parent (fitness-weighted)
   ├─ Sample inspirations (top-k, recency-weighted)
   ├─ Decide: crossover or mutation?
   │
   ├─ If mutation:
   │  ├─ Build prompt (parent + inspirations + context)
   │  ├─ Call GPT-5.1 → child organism
   │  └─ Create mutation record
   │
   ├─ If crossover:
   │  ├─ Sample second parent
   │  ├─ Uniform crossover → child organism
   │  └─ Create crossover record
   │
   ├─ Evaluate child:
   │  ├─ Convert organism → CheTercieuxQueueModel
   │  ├─ Run DES (100,000 timesteps)
   │  ├─ Compute stationary distribution
   │  └─ Calculate welfare W
   │
   ├─ Add child to candidate pool
   │
   └─ If batch complete:
      ├─ Apply selection pressure (top 10%)
      ├─ Add survivors to database
      └─ Update adaptive mutation temperature

3. Output
   ├─ Best organism
   ├─ History (fitness progression)
   └─ Visualizations (if requested)
```

### Mutation Prompt Structure

```
System Prompt:
├─ Problem description (Che-Tercieux queue design)
├─ Economic context (welfare function, parameters)
├─ Parent organism:
│  ├─ Entry/exit rules (code)
│  ├─ Queue discipline, information rule
│  ├─ Fitness score
│  └─ Simulation statistics
├─ Inspiration organisms (top performers):
│  └─ Similar structure for each
├─ Lineage history (recent successful mutations)
├─ Successful patterns (what tends to work)
└─ Mutation strength guidance:
   ├─ Small: Fine-tune one parameter
   ├─ Medium: Adjust 1-2 parameters
   ├─ Large: Restructure rules
   └─ Radical: Completely rethink approach
```

## Key Design Decisions

### 1. LLM as Mutation Operator

**Rationale:**
- LLMs can reason about economic incentives
- Generate targeted mutations more likely to improve fitness
- Leverage prior knowledge about mechanism design

**Trade-offs:**
- More expensive than random mutation (API calls)
- Less predictable than deterministic operators
- Requires careful prompt engineering

### 2. Selection Pressure (Top 10%)

**Rationale:**
- Prevents population explosion
- Focuses search on promising regions
- Mimics natural selection

**Trade-offs:**
- May discard potentially good organisms early
- Requires careful tuning of pressure level

### 3. Adaptive Mutation Strength

**Rationale:**
- Balance exploration vs. exploitation
- Increase diversity when stuck
- Fine-tune when improving

**Trade-offs:**
- Temperature parameters need tuning
- May oscillate if thresholds poorly chosen

### 4. ThreadPoolExecutor (Not ProcessPoolExecutor)

**Rationale:**
- LLM API calls are I/O-bound (network)
- Threads sufficient for I/O-bound tasks
- Simpler shared state (database)

**Trade-offs:**
- GIL limits CPU-bound parallelism
- For CPU-bound simulation, multiprocessing would be better
- Current bottleneck is LLM calls, not simulation

### 5. Discrete-Event Simulation

**Rationale:**
- Accurate representation of stochastic queue dynamics
- Can handle complex state-dependent rules
- Computes true stationary distribution

**Trade-offs:**
- Slower than analytical solutions (when available)
- Requires sufficient simulation time for convergence
- Stochastic → need multiple runs for confidence

## Performance Considerations

### Bottlenecks

1. **LLM API Calls**: ~1-3 seconds per mutation
   - Mitigation: Parallel workers, batch processing
   - Future: Local LLM, caching

2. **Simulation Time**: ~0.1-1 second per evaluation
   - Mitigation: Parallel evaluation, reduce timesteps for early generations
   - Future: GPU-accelerated simulation, analytical approximations

3. **Population Size**: O(N) operations for sampling
   - Mitigation: Incremental weight caching, heap-based top-k
   - Future: Approximate sampling (MCMC, reservoir sampling)

### Optimization Opportunities

- **Multiprocessing**: Replace ThreadPoolExecutor with ProcessPoolExecutor for CPU-bound simulation
- **GPU Simulation**: Vectorize simulations using JAX/PyTorch
- **Caching**: Cache simulation results for identical organisms
- **Early Stopping**: Stop simulation early if fitness clearly poor
- **Analytical Shortcuts**: Use analytical solutions when queue is simple

## Extension Points

### Adding New Queue Disciplines

1. Add enum value to `QueueDiscipline` in `evolve_types.py`
2. Implement belief update logic in `Agent.update_belief_on_service()`
3. Update service selection logic in `QueueSimulator`

### Adding New Information Rules

1. Add enum value to `InformationRule` in `evolve_types.py`
2. Implement observation logic in `QueueSimulator._get_entry_probability()`

### Customizing Mutation Prompts

1. Modify `build_mutation_prompt()` in `utils.py`
2. Add domain-specific context
3. Include relevant economic theory

### Different Fitness Functions

1. Modify `evaluate_designer_performance()` in `evaluator.py`
2. Or pass custom evaluator to `evaluate_organism()`

### Alternative Evolutionary Operators

1. Implement new operator (e.g., local search, gradient-based)
2. Add to evolution loop in `main.py`
3. Update selection logic if needed

## Future Improvements

See codebase quality assessment (65th percentile) for recommendations:
- Comprehensive test suite
- Replace `eval()` with AST parsing
- Better error handling
- Logging infrastructure
- Performance profiling
- CI/CD pipeline

